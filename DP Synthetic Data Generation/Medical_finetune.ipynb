{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/awslabs/fast-differential-privacy.git\n",
      "  Cloning https://github.com/awslabs/fast-differential-privacy.git to /private/var/folders/th/lhv5svr57tl9sd7p465ddg3h0000gn/T/pip-req-build-dnb74kyp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/awslabs/fast-differential-privacy.git /private/var/folders/th/lhv5svr57tl9sd7p465ddg3h0000gn/T/pip-req-build-dnb74kyp\n",
      "  Resolved https://github.com/awslabs/fast-differential-privacy.git to commit bd81a45ae1badcdc773c5306ebfcb1fafef43966\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/awslabs/fast-differential-privacy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (4.39.3)\n",
      "Requirement already satisfied: torch in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: filelock in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch scikit-learn codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/kyradresen/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from fastDP import PrivacyEngine\n",
    "import transformers, torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>age_related_sentence</th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>med_masked_transcriptions</th>\n",
       "      <th>pii_masked_transcriptions</th>\n",
       "      <th>synthetic_sentence_nodp_temp0.6_topk50</th>\n",
       "      <th>synthetic_sentence_eps16_temp1_topk50</th>\n",
       "      <th>synthetic_sentence_eps8_temp1_topk100</th>\n",
       "      <th>synthetic_sentence_eps3_temp1_topk100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neurology</td>\n",
       "      <td>CC:, Confusion and slurred speech.,HX , (prima...</td>\n",
       "      <td>HX , (primarily obtained from boyfriend): This...</td>\n",
       "      <td>(primarily obtained from boyfriend): This 31 y...</td>\n",
       "      <td>43</td>\n",
       "      <td>(primarily obtained from boyfriend): This[AGE]...</td>\n",
       "      <td>(primarily obtained from boyfriend): This[AGE]...</td>\n",
       "      <td>[BOS]Neurology[SEP]The patient is a 55-year-ol...</td>\n",
       "      <td>[BOS]Neurology[SEP]The patient is a 38-year-ol...</td>\n",
       "      <td>[BOS]Neurology[SEP]Shitetron[SEPSEP]The patien...</td>\n",
       "      <td>[BOS]Neurology[SEP]The patient is a 42-year-ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiovascular/Pulmonary</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES,Airway obstruction seco...</td>\n",
       "      <td>INDICATIONS FOR SURGERY,The patient is a 50-ye...</td>\n",
       "      <td>The patient is a 50-year-old white male with h...</td>\n",
       "      <td>72</td>\n",
       "      <td>The patient is a[AGE] white[SEX] with history ...</td>\n",
       "      <td>The patient is a[AGE] white[SEX] with history ...</td>\n",
       "      <td>[BOS]Cardiovascular/Pulmonary[SEP]The patient ...</td>\n",
       "      <td>[BOS]Cardiovascular/Pulmonary[SEP]The patient ...</td>\n",
       "      <td>[BOS]Cardiovascular/Pulmonary[SEP]This is a yo...</td>\n",
       "      <td>[BOS]Cardiovascular/Pulmonary[SEP]The patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PROCEDURE: , Elective male sterilization via b...</td>\n",
       "      <td>PROCEDURE: , Elective male sterilization via b...</td>\n",
       "      <td>Elective male sterilization via bilateral vase...</td>\n",
       "      <td>43</td>\n",
       "      <td>Elective male sterilization via bilateral vase...</td>\n",
       "      <td>Elective male sterilization via bilateral vase...</td>\n",
       "      <td>[BOS]Urology[SEP]The patient was brought to th...</td>\n",
       "      <td>[BOS]Urology[SEP]Cardiovascular/Pulmonary[SEP:...</td>\n",
       "      <td>[BOS]Urology[SEP]HISTORY OF DISHISTORY AND BEE...</td>\n",
       "      <td>[BOS]Urology[SEP]This is a 38-year-old with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urology</td>\n",
       "      <td>DESCRIPTION:,  The patient was placed in the s...</td>\n",
       "      <td>DESCRIPTION:, The patient was placed in the su...</td>\n",
       "      <td>The patient was placed in the supine position ...</td>\n",
       "      <td>44</td>\n",
       "      <td>The patient was placed in the supine position ...</td>\n",
       "      <td>The patient was placed in the supine position ...</td>\n",
       "      <td>[BOS]Urology[SEP]The patient is a 64-year-old ...</td>\n",
       "      <td>[BOS]Urology[SEP]The patient with a history of...</td>\n",
       "      <td>[BOS]Urology[SEP]Ophytology[SEPURE] The patien...</td>\n",
       "      <td>[BOS]Urology[SEP]The patient is referred to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urology</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Voluntary sterility....</td>\n",
       "      <td>INDICATIONS FOR PROCEDURE:  ,A gentleman who i...</td>\n",
       "      <td>A gentleman who is here today requesting volun...</td>\n",
       "      <td>63</td>\n",
       "      <td>A gentleman who is here today requesting volun...</td>\n",
       "      <td>A gentleman who is here today requesting volun...</td>\n",
       "      <td>[BOS]Urology[SEP]HISTORY OF PRESENT ILLNESS:, ...</td>\n",
       "      <td>[BOS]Urology[SEP]HISTORY OF THE PROCEDURE:, Th...</td>\n",
       "      <td>[BOS]Urology[SEP]The patient is a 1-year-old f...</td>\n",
       "      <td>[BOS]Urology[SEP]Neurology[SEPUE]Neuroptic[SEP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          medical_specialty  \\\n",
       "0                 Neurology   \n",
       "1  Cardiovascular/Pulmonary   \n",
       "2                   Urology   \n",
       "3                   Urology   \n",
       "4                   Urology   \n",
       "\n",
       "                                       transcription  \\\n",
       "0  CC:, Confusion and slurred speech.,HX , (prima...   \n",
       "1  PREOPERATIVE DIAGNOSES,Airway obstruction seco...   \n",
       "2  PROCEDURE: , Elective male sterilization via b...   \n",
       "3  DESCRIPTION:,  The patient was placed in the s...   \n",
       "4  PREOPERATIVE DIAGNOSIS: , Voluntary sterility....   \n",
       "\n",
       "                                age_related_sentence  \\\n",
       "0  HX , (primarily obtained from boyfriend): This...   \n",
       "1  INDICATIONS FOR SURGERY,The patient is a 50-ye...   \n",
       "2  PROCEDURE: , Elective male sterilization via b...   \n",
       "3  DESCRIPTION:, The patient was placed in the su...   \n",
       "4  INDICATIONS FOR PROCEDURE:  ,A gentleman who i...   \n",
       "\n",
       "                                      extracted_text  word_count  \\\n",
       "0  (primarily obtained from boyfriend): This 31 y...          43   \n",
       "1  The patient is a 50-year-old white male with h...          72   \n",
       "2  Elective male sterilization via bilateral vase...          43   \n",
       "3  The patient was placed in the supine position ...          44   \n",
       "4  A gentleman who is here today requesting volun...          63   \n",
       "\n",
       "                           med_masked_transcriptions  \\\n",
       "0  (primarily obtained from boyfriend): This[AGE]...   \n",
       "1  The patient is a[AGE] white[SEX] with history ...   \n",
       "2  Elective male sterilization via bilateral vase...   \n",
       "3  The patient was placed in the supine position ...   \n",
       "4  A gentleman who is here today requesting volun...   \n",
       "\n",
       "                           pii_masked_transcriptions  \\\n",
       "0  (primarily obtained from boyfriend): This[AGE]...   \n",
       "1  The patient is a[AGE] white[SEX] with history ...   \n",
       "2  Elective male sterilization via bilateral vase...   \n",
       "3  The patient was placed in the supine position ...   \n",
       "4  A gentleman who is here today requesting volun...   \n",
       "\n",
       "              synthetic_sentence_nodp_temp0.6_topk50  \\\n",
       "0  [BOS]Neurology[SEP]The patient is a 55-year-ol...   \n",
       "1  [BOS]Cardiovascular/Pulmonary[SEP]The patient ...   \n",
       "2  [BOS]Urology[SEP]The patient was brought to th...   \n",
       "3  [BOS]Urology[SEP]The patient is a 64-year-old ...   \n",
       "4  [BOS]Urology[SEP]HISTORY OF PRESENT ILLNESS:, ...   \n",
       "\n",
       "               synthetic_sentence_eps16_temp1_topk50  \\\n",
       "0  [BOS]Neurology[SEP]The patient is a 38-year-ol...   \n",
       "1  [BOS]Cardiovascular/Pulmonary[SEP]The patient ...   \n",
       "2  [BOS]Urology[SEP]Cardiovascular/Pulmonary[SEP:...   \n",
       "3  [BOS]Urology[SEP]The patient with a history of...   \n",
       "4  [BOS]Urology[SEP]HISTORY OF THE PROCEDURE:, Th...   \n",
       "\n",
       "               synthetic_sentence_eps8_temp1_topk100  \\\n",
       "0  [BOS]Neurology[SEP]Shitetron[SEPSEP]The patien...   \n",
       "1  [BOS]Cardiovascular/Pulmonary[SEP]This is a yo...   \n",
       "2  [BOS]Urology[SEP]HISTORY OF DISHISTORY AND BEE...   \n",
       "3  [BOS]Urology[SEP]Ophytology[SEPURE] The patien...   \n",
       "4  [BOS]Urology[SEP]The patient is a 1-year-old f...   \n",
       "\n",
       "               synthetic_sentence_eps3_temp1_topk100  \n",
       "0  [BOS]Neurology[SEP]The patient is a 42-year-ol...  \n",
       "1  [BOS]Cardiovascular/Pulmonary[SEP]The patient ...  \n",
       "2  [BOS]Urology[SEP]This is a 38-year-old with a ...  \n",
       "3  [BOS]Urology[SEP]The patient is referred to a ...  \n",
       "4  [BOS]Urology[SEP]Neurology[SEPUE]Neuroptic[SEP...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=\"/Users/kyradresen/MasterThesis_MedTextPrivacy/data/2016r_mtsamples_final.csv\"\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune DistilGPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable components:  77 ; Number of trainable layers:  40\n",
      ">>>>>>>>>>>>>>>>> Applying  automatic  per-sample gradient clipping.\n",
      ">>>>>>>>>>>>>>>>> Block heads for per-sample gradient clipping are defined as: ['transformer.wte']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed.\n",
      "Epoch 2 completed.\n",
      "Epoch 3 completed.\n",
      "Epoch 4 completed.\n",
      "Epoch 5 completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from fastDP import PrivacyEngine  # Ensure fastDP is installed\n",
    "from codecarbon import track_emissions\n",
    "\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the model and tokenizer, and move the model to the specified device\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# Add a padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Dataset class for multi-class classification\n",
    "class MedicalSpecialtyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        specialty_label = f\"{self.labels[idx]}[SEP]\"\n",
    "        text = f\"[BOS]{specialty_label}{self.texts[idx]}\"\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "\n",
    "        # The target is the same as input_ids but shifted by one position\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[target_ids == self.tokenizer.pad_token_id] = -100  # Ignore padding token\n",
    "\n",
    "        return input_ids, attention_mask, target_ids\n",
    "\n",
    "# Load your dataframe here\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Extract texts and labels from the dataframe\n",
    "texts = df['extracted_text'].tolist()\n",
    "labels = df['medical_specialty'].tolist()\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.05)\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = MedicalSpecialtyDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = MedicalSpecialtyDataset(val_texts, val_labels, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# Define the PrivacyEngine\n",
    "privacy_engine = PrivacyEngine(\n",
    "    model,\n",
    "    batch_size=64,\n",
    "    sample_size=len(train_dataset),\n",
    "    epochs=5,\n",
    "    target_epsilon=16,\n",
    "    clipping_fn='automatic',\n",
    "    clipping_mode='MixOpt',\n",
    "    origin_params=None,\n",
    "    clipping_style='all-layer',\n",
    ")\n",
    "\n",
    "# Attach the PrivacyEngine to the optimizer\n",
    "privacy_engine.attach(optimizer)\n",
    "\n",
    "# Training loop\n",
    "@track_emissions\n",
    "def training_loop():\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, target_ids = [x.to(device) for x in batch]\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=target_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} completed.\")\n",
    "\n",
    "# Run the training loop\n",
    "training_loop()\n",
    "\n",
    "# Detach and save the privacy engine state\n",
    "privacy_engine.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./trained_model_with_classifier_distilgpt2_dpeps16_2016\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to save the model and tokenizer\n",
    "save_directory = \"./trained_model_with_classifier_distilgpt2_dpeps16_2016\"\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "import os\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic sentences generated and saved to synthetic_data_bossep.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to generate synthetic sentences with medical specialty label\n",
    "def generate_synthetic_sentence(model, tokenizer, label, max_length=80):\n",
    "    model.eval()\n",
    "    specialty_label = f\"{label}[SEP]\"\n",
    "    input_ids = tokenizer.encode(f\"[BOS]{specialty_label}\", return_tensors='pt').to(device)\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        no_repeat_ngram_size=4,  # Avoid repeating n-grams\n",
    "        do_sample=True,  # Enable sampling\n",
    "        top_k=50,  # Top-k sampling\n",
    "        top_p=0.95,  # Top-p sampling (nucleus sampling)\n",
    "        temperature=1.0\n",
    "    )\n",
    "    generated_sentence = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_sentence\n",
    "\n",
    "# Generate synthetic sentences for each row in the dataframe\n",
    "synthetic_sentences = []\n",
    "for index, row in df.iterrows():\n",
    "    specialty = row['medical_specialty']\n",
    "    synthetic_sentence = generate_synthetic_sentence(model, tokenizer, specialty, max_length=80)\n",
    "    synthetic_sentences.append(synthetic_sentence)\n",
    "\n",
    "# Append the synthetic sentences to the dataframe\n",
    "df['synthetic_sentence_eps16_temp1_topk50'] = synthetic_sentences\n",
    "\n",
    "# Save the dataframe with the synthetic sentences\n",
    "df.to_csv('synthetic_sentence_eps16_temp1_topk50.csv', index=False)\n",
    "\n",
    "print(\"Synthetic sentences generated and saved to synthetic_data_bossep.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
